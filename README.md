100% Python WebCrawler
======================

This is a 100% in python written WebCrawler. It uses the requests library to get
any HTML pages defined in a text document and appends the document with
additional links form the Website. It automatically checks for duplication and
non-working / non-html links and excludes those.

Setup
-----

The program can be defined to scan a specific base URL and output all
non-working, as well as working URLs. This is helpful to quickly check your own
Website for outdated links. It can also be used as a simple WebCrawler.

Multi â€“ Processing
------------------

The Script is now simplified and may be used with multiprocessing to increase
efficiency overall and use the available resources up to 100%.

Work in Progress
----------------

This Project is still work in progress, even though the base WebCrawler works to
100%, the documentation and interface is not finished yet.
